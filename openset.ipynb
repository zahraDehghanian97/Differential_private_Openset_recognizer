{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CWVoojXo9KKyLUj4Gw-2tj1KQ4QTxO84",
      "authorship_tag": "ABX9TyPSMQGEQBNMI9Vl+glzBqj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c76004cf498547b8abe43290d796cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2e127a8f9e64d118f7e3cacccbe2937",
              "IPY_MODEL_c8ce41d8f20a4314bd7ac77e361dff47",
              "IPY_MODEL_cc54d0afa8e3453e9ae3931178b67b6d"
            ],
            "layout": "IPY_MODEL_62baec02b8a3492a841ffc28300152bd"
          }
        },
        "c2e127a8f9e64d118f7e3cacccbe2937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527e5bd139a24dbf89be49c4afcace70",
            "placeholder": "​",
            "style": "IPY_MODEL_5af5317595cf4f82bc03ec40a962e0d1",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "c8ce41d8f20a4314bd7ac77e361dff47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95758efdc8964f62969a616cd0a58152",
            "max": 49335454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5516019999c24f96aca9404107876789",
            "value": 49335454
          }
        },
        "cc54d0afa8e3453e9ae3931178b67b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ca21350cc44d3dbb09c3276bb6cfed",
            "placeholder": "​",
            "style": "IPY_MODEL_4303dfdfb7024439ad71df08f42b64ca",
            "value": " 49.3M/49.3M [00:00&lt;00:00, 54.2MB/s]"
          }
        },
        "62baec02b8a3492a841ffc28300152bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527e5bd139a24dbf89be49c4afcace70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af5317595cf4f82bc03ec40a962e0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95758efdc8964f62969a616cd0a58152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5516019999c24f96aca9404107876789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9ca21350cc44d3dbb09c3276bb6cfed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4303dfdfb7024439ad71df08f42b64ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/Openset_recognizer/blob/master/openset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz_ODdWLY7ax",
        "outputId": "55eb7c84-1a1c-489f-e747-2740aefeb6d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m204.8/224.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65hmCjBgY-k1",
        "outputId": "5d3cfec8-31f7-4f63-95b3-a0293fa2da1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m2.0/2.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ],
      "metadata": {
        "id": "aR6X00q4Yy4x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed=2023)\n",
        "\n",
        "class ImageDataset:\n",
        "  def __init__(self, data, labels, n_classes, ls_eps, transform):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.ls_eps = ls_eps\n",
        "    self.n_classes = n_classes\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.ls_eps > 0:\n",
        "      label = self.label_smoothing(self.labels[idx])\n",
        "    else:\n",
        "      label = self.labels[idx]\n",
        "    return self.transform(Image.fromarray(self.data[idx])), torch.tensor(label)\n",
        "\n",
        "  def view(self, idx):\n",
        "    return self.data[idx], self.label[idx]\n",
        "\n",
        "  def label_smoothing(self, label):\n",
        "    out = np.ones(self.n_classes) * self.ls_eps / (self.n_classes - 1)\n",
        "    out[label] = 1 - self.ls_eps\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "K1MFhpKeNDHD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# These values, specific to the CIFAR10 dataset, are assumed to be known.\n",
        "# If necessary, they can be computed with modest privacy budgets.\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD_DEV),\n",
        "])\n",
        "N = 10\n",
        "feature_dim = 128\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "model.classifier = nn.Sequential(\n",
        "        nn.Linear(1536, feature_dim),\n",
        "        nn.BatchNorm1d(feature_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(feature_dim, N))\n",
        "\n",
        "DATA_ROOT = '../cifar10'\n",
        "train_dataset = CIFAR10(\n",
        "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(ModuleValidator.validate(model, strict=False))\n",
        "model = ModuleValidator.fix(model)\n",
        "print(ModuleValidator.validate(model, strict=False))\n",
        "print(\"validator done\")\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)\n",
        "\n",
        "privacy_engine = PrivacyEngine()\n",
        "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_loader,\n",
        "    target_epsilon=1,\n",
        "    target_delta=1e-6,\n",
        "    epochs=1000,\n",
        "    max_grad_norm=1.0,\n",
        "    grad_sample_mode=\"ew\"\n",
        "    )\n",
        "print(\"privacy engine initialized\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "c76004cf498547b8abe43290d796cef1",
            "c2e127a8f9e64d118f7e3cacccbe2937",
            "c8ce41d8f20a4314bd7ac77e361dff47",
            "cc54d0afa8e3453e9ae3931178b67b6d",
            "62baec02b8a3492a841ffc28300152bd",
            "527e5bd139a24dbf89be49c4afcace70",
            "5af5317595cf4f82bc03ec40a962e0d1",
            "95758efdc8964f62969a616cd0a58152",
            "5516019999c24f96aca9404107876789",
            "a9ca21350cc44d3dbb09c3276bb6cfed",
            "4303dfdfb7024439ad71df08f42b64ca"
          ]
        },
        "id": "y_Spj-qh3SEU",
        "outputId": "e46124cf-9f1b-47ce-aab0-496984fcf340"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76004cf498547b8abe43290d796cef1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 52931357.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../cifar10/cifar-10-python.tar.gz to ../cifar10\n",
            "[ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\")]\n",
            "[]\n",
            "validator done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
            "  z = np.log((np.exp(t) + q - 1) / q)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "privacy engine initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axYzE20TYpdi",
        "outputId": "6f5ce465-0825-47e1-a317-2d358bdb4df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\")]\n",
            "[]\n",
            "validator done\n",
            "privacy engine initialized\n",
            "Using sigma=0.35675048828125 and C=1.2\n",
            "######## EPOCH 1/2 started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:34<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN done: loss = 2.0485, accuracy = 11.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> best model saved. ACC=18.18\n",
            "VAL done: loss = 2.0559, accuracy = 18.18\n",
            "######## EPOCH 2/2 started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:37<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN done: loss = 1.9510, accuracy = 19.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> best model saved. ACC=20.00\n",
            "VAL done: loss = 2.0104, accuracy = 20.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:24<00:00,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Classification Accuracy =  0.16829745596868884\n",
            "MLS stats: mean=0.6510061261238651, std=0.20510164598498543\n",
            "CLOSED DATA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36/36 [00:05<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPEN DATA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Openset recognition accuracy =  0.7663043478260869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36/36 [00:07<00:00,  4.99it/s]\n",
            "100%|██████████| 10/10 [00:01<00:00,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Separator Accuracy =  78.80434782608697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "class OpensetRecognizer(nn.Module):\n",
        "  def __init__(self, data_path, feature_dim):\n",
        "    super().__init__()\n",
        "    self.data_path = data_path\n",
        "    self.train_transform = transforms.Compose([\n",
        "        transforms.RandAugment(num_ops=6, magnitude=10, num_magnitude_bins=51),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "    self.val_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "    self._load_data()\n",
        "    self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    self.feature_dim = feature_dim\n",
        "    self._load_model(feature_dim)\n",
        "    self.to(self.device)\n",
        "\n",
        "  def train_collate(self, data):\n",
        "    img, labels = zip(*data)\n",
        "    img = torch.stack(img).float()\n",
        "    labels = torch.stack(labels).float()\n",
        "    return img, labels\n",
        "\n",
        "  def val_collate(self, data):\n",
        "    img, labels = zip(*data)\n",
        "    img = torch.stack(img).float()\n",
        "    labels = torch.stack(labels).long()\n",
        "    return img, labels\n",
        "\n",
        "  def _load_data(self):\n",
        "    train_data = pickle.load(open(os.path.join(self.data_path, 'train_data.pickle'), 'rb'))\n",
        "    train_labels = pickle.load(open(os.path.join(self.data_path, 'train_labels.pickle'), 'rb'))\n",
        "    train_labels_set = sorted(list(set(train_labels)))\n",
        "    train_labels_mapping = {train_labels_set[i]:i for i in range(len(train_labels_set))}\n",
        "    train_data = np.stack(train_data)\n",
        "    train_labels = np.array([train_labels_mapping[item] for item in train_labels])\n",
        "    self.N = len(train_labels_set)\n",
        "    val_inds = []\n",
        "    train_inds = []\n",
        "    for i in range(self.N):\n",
        "      all_idx = rng.permutation(np.nonzero(train_labels == i)[0])\n",
        "      val_idx = all_idx[:int(0.1 * len(all_idx))]\n",
        "      train_idx = all_idx[int(0.1 * len(all_idx)):]\n",
        "      train_inds.append(train_idx)\n",
        "      val_inds.append(val_idx)\n",
        "    val_inds = np.concatenate(val_inds)\n",
        "    train_inds = np.concatenate(train_inds)\n",
        "    val_data = train_data[val_inds]\n",
        "    train_data = train_data[train_inds]\n",
        "    val_labels = train_labels[val_inds]\n",
        "    train_labels = train_labels[train_inds]\n",
        "    train_dataset = ImageDataset(train_data, train_labels, n_classes=7, ls_eps=0.1, transform=self.train_transform)\n",
        "    val_dataset = ImageDataset(val_data, val_labels, n_classes=7, ls_eps=0, transform=self.val_transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=self.train_collate, drop_last=False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=self.val_collate, drop_last=False)\n",
        "    self.loaders = {'train': train_loader, 'val': val_loader}\n",
        "\n",
        "  def CEWithSmoothLabels(self, output, target):\n",
        "    log_pred = F.log_softmax(output, dim=-1)\n",
        "    return torch.mean(torch.sum(-log_pred * target, dim=-1))\n",
        "\n",
        "  def _load_model(self, feature_dim):\n",
        "    self.model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "    self.model.classifier = nn.Sequential(\n",
        "        nn.Linear(1536, feature_dim),\n",
        "        nn.BatchNorm1d(feature_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(feature_dim, self.N))\n",
        "    # params_to_optim = []\n",
        "    # for n, p in self.model.named_parameters():\n",
        "    #   if n.startswith('classifier') or n.startswith('bn2') or n.startswith('conv_head'):\n",
        "    #     p.requires_grad = True\n",
        "    #     params_to_optim.append(p)\n",
        "    #   else:\n",
        "    #     p.requires_grad = False\n",
        "    # self.model_params = params_to_optim\n",
        "\n",
        "  def _prepare_training(self, n_epochs):\n",
        "    self.optimizer = torch.optim.Adam(self.model_params, lr=1e-4, weight_decay=1e-4)\n",
        "    self.scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=self.optimizer, max_lr=1e-3, epochs=n_epochs, steps_per_epoch=len(self.loaders['train']))\n",
        "    train_criterion = self.CEWithSmoothLabels\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    self.criterions = {'train': train_criterion, 'val': val_criterion}\n",
        "\n",
        "  def _prepare_training_with_privacy(self, n_epochs,epsilon,delta,max_grad_norm):\n",
        "    #validate model to change not private part\n",
        "    print(ModuleValidator.validate(self.model, strict=False))\n",
        "    self.model = ModuleValidator.fix(self.model)\n",
        "    print(ModuleValidator.validate(self.model, strict=False))\n",
        "    print(\"validator done\")\n",
        "    # choose trainable layer in new model\n",
        "    params_to_optim = []\n",
        "    for n, p in self.model.named_parameters():\n",
        "      if n.startswith('classifier')  or n.startswith('conv_head'):\n",
        "        p.requires_grad = True\n",
        "        params_to_optim.append(p)\n",
        "      else:\n",
        "        p.requires_grad = False\n",
        "    self.model_params = params_to_optim\n",
        "    # change self.model_param --> self.model.parameters()\n",
        "    self.optimizer = torch.optim.Adam(self.model_params, lr=1e-4, weight_decay=1e-4)\n",
        "    # self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    self.scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=self.optimizer, max_lr=1e-3, epochs=n_epochs, steps_per_epoch=len(self.loaders['train']))\n",
        "    train_criterion = self.CEWithSmoothLabels\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    self.criterions = {'train': train_criterion, 'val': val_criterion}\n",
        "    # add privacy engine\n",
        "    privacy_engine = PrivacyEngine()\n",
        "    self.model, self.optimizer, self.loaders['train'] = privacy_engine.make_private_with_epsilon(\n",
        "        module=self.model,\n",
        "        optimizer=self.optimizer,\n",
        "        data_loader=self.loaders['train'],\n",
        "        epochs=n_epochs,\n",
        "        target_epsilon=epsilon,\n",
        "        target_delta=delta,\n",
        "        max_grad_norm=max_grad_norm,\n",
        "        grad_sample_mode=\"hooks\")\n",
        "    print(\"privacy engine initialized\")\n",
        "    print(f\"Using sigma={self.optimizer.noise_multiplier} and C={max_grad_norm}\")\n",
        "\n",
        "\n",
        "  def train_model(self, n_epochs):\n",
        "    # self._prepare_training(n_epochs)\n",
        "    self._prepare_training_with_privacy(n_epochs,epsilon=0.5,delta=0.5,max_grad_norm=1.2)\n",
        "    losses = {'train': [], 'val': []}\n",
        "    accs = {'train': [], 'val': []}\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(n_epochs):\n",
        "      print(f\"######## EPOCH {epoch + 1}/{n_epochs} started\")\n",
        "      for mode in ['train', 'val']:\n",
        "        if mode == 'train':\n",
        "          self.model.train()\n",
        "        else:\n",
        "          self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        count = 0\n",
        "        for img, label in tqdm(self.loaders[mode]):\n",
        "          img = img.to(self.device)\n",
        "          label = label.to(self.device)\n",
        "          bsz = len(label)\n",
        "          with torch.set_grad_enabled(mode == 'train'):\n",
        "            output = self.model(img)\n",
        "          loss = self.criterions[mode](output, label)\n",
        "          total_loss += loss.item() * bsz\n",
        "          target = label if mode == 'val' else torch.argmax(label, dim=-1)\n",
        "          pred = torch.argmax(output, dim=-1)\n",
        "          total_acc += torch.sum(pred == target).item()\n",
        "          count += bsz\n",
        "          if mode == 'train':\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "            self.scheduler.step()\n",
        "        losses[mode].append(total_loss / count)\n",
        "        accs[mode].append(total_acc / count * 100)\n",
        "        if mode == 'val':\n",
        "          if accs[mode][-1] > best_acc:\n",
        "            best_acc = accs[mode][-1]\n",
        "            torch.save(self.model.state_dict(), f'model_{self.feature_dim}.pt')\n",
        "            print(f\"--> best model saved. ACC={best_acc:.2f}\")\n",
        "        print(f\"{mode.upper()} done: loss = {losses[mode][-1]:.4f}, accuracy = {accs[mode][-1]:.2f}\")\n",
        "    self.model.load_state_dict(torch.load(f'model_{self.feature_dim}.pt'))\n",
        "    return losses, accs\n",
        "  def prepare_detection_model(self):\n",
        "    mls_closed = []\n",
        "    self.model.eval()\n",
        "    total_acc = 0\n",
        "    count = 0\n",
        "    for img, label in tqdm(self.loaders['train']):\n",
        "      img = img.to(self.device)\n",
        "      label = label.to(self.device)\n",
        "      bsz = len(label)\n",
        "      with torch.no_grad():\n",
        "        output = self.model(img)\n",
        "      mls_closed += torch.amax(output, dim=-1).cpu().numpy().tolist()\n",
        "      pred = torch.argmax(output, dim=-1)\n",
        "      label = torch.argmax(label, dim=-1)\n",
        "      total_acc += torch.sum(pred == label).item()\n",
        "      count += bsz\n",
        "    acc = total_acc / count\n",
        "    self.mls_closed_stats = {\n",
        "      'mean': np.mean(mls_closed),\n",
        "      'std': np.std(mls_closed)\n",
        "    }\n",
        "    print(\"\\nTrain Classification Accuracy = \", acc)\n",
        "    print(f'MLS stats: mean={self.mls_closed_stats[\"mean\"]}, std={self.mls_closed_stats[\"std\"]}')\n",
        "\n",
        "  def detect_openset(self, sample):\n",
        "    sample = sample.to(self.device)\n",
        "    with torch.no_grad():\n",
        "      output = self.model(sample)\n",
        "    tau = (torch.amax(output, dim=-1) - self.mls_closed_stats['mean']) / self.mls_closed_stats['std']\n",
        "    return (torch.abs(tau) > 2).bool().cpu().numpy()\n",
        "\n",
        "  def openset_evaluation(self, testloader, openloader):\n",
        "    self.model.eval()\n",
        "    acc = 0\n",
        "    count = 0\n",
        "    print(\"CLOSED DATA\")\n",
        "    for img, label in tqdm(testloader):\n",
        "      img = img.to(self.device)\n",
        "      label = label.to(self.device)\n",
        "      bsz = len(label)\n",
        "      with torch.no_grad():\n",
        "        if_open = self.detect_openset(img)\n",
        "      acc += np.sum(~if_open)\n",
        "      count += len(if_open)\n",
        "    print(\"OPEN DATA\")\n",
        "    for img, label in tqdm(openloader):\n",
        "      img = img.to(self.device)\n",
        "      label = label.to(self.device)\n",
        "      bsz = len(label)\n",
        "      with torch.no_grad():\n",
        "        if_open = self.detect_openset(img)\n",
        "      acc += np.sum(if_open)\n",
        "      count += len(if_open)\n",
        "    print('Openset recognition accuracy = ', acc / count)\n",
        "    return acc / count\n",
        "\n",
        "  def openset_best_separator_evaluation(self, test_loader, open_loader):\n",
        "    self.model.eval()\n",
        "    mls_closed = []\n",
        "    for img, label in tqdm(test_loader):\n",
        "      img = img.to(self.device)\n",
        "      label = label.to(self.device)\n",
        "      bsz = len(label)\n",
        "      with torch.no_grad():\n",
        "        output = self.model(img)\n",
        "      mls_closed += torch.amax(output, dim=-1).cpu().numpy().tolist()\n",
        "    mls_open = []\n",
        "    for img, label in tqdm(open_loader):\n",
        "      img = img.to(self.device)\n",
        "      label = label.to(self.device)\n",
        "      bsz = len(label)\n",
        "      with torch.no_grad():\n",
        "        output = self.model(img)\n",
        "      mls_open += torch.amax(output, dim=-1).cpu().numpy().tolist()\n",
        "    x = sorted(mls_open + mls_closed)\n",
        "    min_item = 0\n",
        "    min_value = 1000\n",
        "    for node in x:\n",
        "      e1 = len([item for item in mls_open if item >= node])\n",
        "      e2 = len([item for item in mls_closed if item < node])\n",
        "      if e1 + e2 < min_value:\n",
        "        min_value = e1 + e2\n",
        "        min_item = node\n",
        "    print(\"Best Separator Accuracy = \", (1 - min_value / len(x)) * 100)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  data_path = '/content/drive/MyDrive/Sample_Data/data/'\n",
        "  openset_model = OpensetRecognizer(data_path=data_path, feature_dim=128)\n",
        "  losses, accs = openset_model.train_model(n_epochs=2)\n",
        "  json.dump({'accs': accs, 'losses': losses}, open('stats.json', 'w'))\n",
        "\n",
        "  test_data = pickle.load(open(os.path.join(data_path, 'test_data.pickle'), 'rb'))\n",
        "  test_labels = pickle.load(open(os.path.join(data_path, 'test_labels.pickle'), 'rb'))\n",
        "\n",
        "  open_data = pickle.load(open(os.path.join(data_path, 'opendata.pickle'), 'rb'))\n",
        "  open_labels = pickle.load(open(os.path.join(data_path, 'open_labels.pickle'), 'rb'))\n",
        "\n",
        "  open_labels_set = sorted(list(set(open_labels)))\n",
        "  test_labels_set = sorted(list(set(test_labels)))\n",
        "  test_labels_mapping = {test_labels_set[i]:i for i in range(len(test_labels_set))}\n",
        "  open_labels_mapping = {open_labels_set[i]:i + len(test_labels_set) for i in range(len(open_labels_set))}\n",
        "\n",
        "  test_data = np.stack(test_data)\n",
        "  open_data = np.stack(open_data)\n",
        "  test_labels = np.array([test_labels_mapping[item] for item in test_labels])\n",
        "  open_labels = np.array([open_labels_mapping[item] for item in open_labels])\n",
        "\n",
        "  test_dataset = ImageDataset(test_data, test_labels, n_classes=7, ls_eps=0, transform=openset_model.val_transform)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, drop_last=False, collate_fn=openset_model.val_collate)\n",
        "\n",
        "  open_dataset = ImageDataset(open_data, test_labels, n_classes=7, ls_eps=0, transform=openset_model.val_transform)\n",
        "  open_loader = DataLoader(open_dataset, batch_size=4, shuffle=False, drop_last=False, collate_fn=openset_model.val_collate)\n",
        "\n",
        "  openset_model.prepare_detection_model()\n",
        "  openset_model.openset_evaluation(test_loader, open_loader)\n",
        "  openset_model.openset_best_separator_evaluation(test_loader, open_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xFCPTHUuTDja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}